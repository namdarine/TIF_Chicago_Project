{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115f1f8f",
   "metadata": {},
   "source": [
    "# Create Racial Distributions of Demographic Data\n",
    "### Author: Lane Hartwig \n",
    "### Date created: 4/10/2023\n",
    "### Last updated: 4/16/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0107675",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0252795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "def createIncomeDistributions(racial_pop, house_income, bloc_bound, path, year):\n",
    "    # copy data to new dataframe\n",
    "    populations = racial_pop[['racial_population_list', 'block group', 'tract', 'geometry']]\n",
    "    populations['area_name'] = np.nan\n",
    "\n",
    "    # iterate by row\n",
    "    for id in range(0,len(populations)):\n",
    "      # combine tract and block group columns together for area name\n",
    "      area = populations.iloc[id][['block group','tract']]\n",
    "      area[1] = '{0:g}'.format(area[1])\n",
    "      string = 'Block {}, Census Tract {}'.format(area[0],area[1])\n",
    "      populations['area_name'][id] = string\n",
    "\n",
    "      # standardize racial_population_list on a [0,1] range\n",
    "      str_list = populations['racial_population_list'][id]\n",
    "      int_list = [int(i) for i in str_list]\n",
    "      if (int_list[0]==0): # set to 0 if no population is recorded for an area\n",
    "        int_list = [0,0,0]\n",
    "        populations['racial_population_list'][id] = int_list\n",
    "      else:\n",
    "        norm_list = [float(i)/int_list[0] for i in int_list]\n",
    "        formatted_norm_list = ['%.2f' % elem for elem in norm_list[1:4]]\n",
    "        populations['racial_population_list'][id] = formatted_norm_list\n",
    "\n",
    "    # organize columns\n",
    "    populations = populations.rename(columns={\"racial_population_list\": \"racial_distribution\"})\n",
    "    populations = populations[['racial_distribution','area_name','geometry']]\n",
    "\n",
    "    # merge dataframes by area names\n",
    "    # householdIncome2022 = householdIncome2022.rename(columns={\"Tract\": \"area_name\"})\n",
    "    mergeDF = pd.merge(populations, house_income, how='inner', on=['area_name'])\n",
    "    data = []\n",
    "\n",
    "    # iterate through rows\n",
    "    for id in range(0,len(mergeDF)):\n",
    "      temp = mergeDF.iloc[id]\n",
    "      race_dist = [float(i) for i in temp[0]]\n",
    "      for j in range(3,len(temp)):\n",
    "        temp[j] = [float(i)*temp[j] for i in race_dist]\n",
    "      data.append(temp)\n",
    "\n",
    "    # dataframe for geiod\n",
    "    geoid = bloc_bound[['block group', 'tract', 'geoid']]\n",
    "    geoid['area_name'] = np.nan\n",
    "\n",
    "    for id in range(0,len(geoid)):\n",
    "      area = geoid.iloc[id][['block group','tract']]\n",
    "      area[1] = '{0:g}'.format(float(area[1]))\n",
    "      string = 'Block {}, Census Tract {}'.format(area[0],area[1])\n",
    "      geoid['area_name'][id] = string\n",
    "\n",
    "    geoid = geoid[['area_name', 'geoid']]\n",
    "\n",
    "    # create new dataframe and clean up the formatting\n",
    "    incomeDistribution = pd.DataFrame(data)\n",
    "    incomeDistribution = pd.merge(incomeDistribution, geoid, how='inner', on=['area_name'])\n",
    "    incomeDistribution = incomeDistribution[['geoid', 'area_name', 'geometry', 'Total','Less than $10,000', '$10,000 to \\$14,999', '\\$15,000 to \\$19,999','$20,000 to \\$24,999', '$25,000 to \\$29,999', '$30,000 to \\$34,999','$35,000 to \\$39,999', '$40,000 to \\$44,999', '$45,000 to \\$49,999','$50,000 to \\$59,999', '$60,000 to \\$74,999', '$75,000 to \\$99,999','$100,000 to \\$124,999', '$125,000 to \\$149,999','$150,000 to \\$199,999', '$200,000 or more']]\n",
    "    incomeDistribution.columns = ['geoid', 'area_name', 'geometry', 'Total','Less than $10,000', '$10,000 to $14,999', '$15,000 to $19,999','$20,000 to $24,999', '$25,000 to $29,999', '$30,000 to $34,999','$35,000 to $39,999', '$40,000 to $44,999', '$45,000 to $49,999','$50,000 to $59,999', '$60,000 to $74,999', '$75,000 to $99,999','$100,000 to $124,999', '$125,000 to $149,999', '$150,000 to $199,999','$200,000 or more']\n",
    "\n",
    "    # save to .csv\n",
    "    incomeDistribution.to_csv(path + 'incomeDistribution{}.csv'.format(year), index=False)\n",
    "\n",
    "     # save to pickle\n",
    "    with open(path + 'incomeDistribution{}.pickle'.format(year), 'wb') as file:\n",
    "        pickle.dump(incomeDistribution, file)\n",
    "\n",
    "    # return new dataframe\n",
    "    return incomeDistribution\n",
    "\n",
    "def createEducationDistributions(racial_pop, education, bloc_bound, path, year):\n",
    "    # copy data to new dataframe\n",
    "    populations = racial_pop[['racial_population_list', 'block group', 'tract', 'geometry']]\n",
    "    populations['area_name'] = np.nan\n",
    "\n",
    "    # iterate by row\n",
    "    for id in range(0,len(populations)):\n",
    "      # combine tract and block group columns together for area name\n",
    "      area = populations.iloc[id][['block group','tract']]\n",
    "      area[1] = '{0:g}'.format(area[1])\n",
    "      string = 'Block {}, Census Tract {}'.format(area[0],area[1])\n",
    "      populations['area_name'][id] = string\n",
    "\n",
    "      # standardize racial_population_list on a [0,1] range\n",
    "      str_list = populations['racial_population_list'][id]\n",
    "      int_list = [int(i) for i in str_list]\n",
    "      if (int_list[0]==0): # set to 0 if no population is recorded for an area\n",
    "        int_list = [0,0,0]\n",
    "        populations['racial_population_list'][id] = int_list\n",
    "      else:\n",
    "        norm_list = [float(i)/int_list[0] for i in int_list]\n",
    "        formatted_norm_list = ['%.2f' % elem for elem in norm_list[1:4]]\n",
    "        populations['racial_population_list'][id] = formatted_norm_list\n",
    "\n",
    "    # organize columns\n",
    "    populations = populations.rename(columns={\"racial_population_list\": \"racial_distribution\"})\n",
    "    populations = populations[['racial_distribution','area_name','geometry']]\n",
    "\n",
    "    # merge dataframes by area names\n",
    "    mergeDF = pd.merge(populations, education, how='inner', on=['area_name'])\n",
    "    data = []\n",
    "\n",
    "    # iterate through rows\n",
    "    for id in range(0,len(mergeDF)):\n",
    "      temp = mergeDF.iloc[id]\n",
    "      race_dist = [float(i) for i in temp[0]]\n",
    "      for j in range(3,len(temp)):\n",
    "        temp[j] = [float(i)*temp[j] for i in race_dist]\n",
    "      data.append(temp)\n",
    "\n",
    "    # dataframe for geiod\n",
    "    geoid = bloc_bound[['block group', 'tract', 'geoid']]\n",
    "    geoid['area_name'] = np.nan\n",
    "\n",
    "    for id in range(0,len(geoid)):\n",
    "      area = geoid.iloc[id][['block group','tract']]\n",
    "      area[1] = '{0:g}'.format(float(area[1]))\n",
    "      string = 'Block {}, Census Tract {}'.format(area[0],area[1])\n",
    "      geoid['area_name'][id] = string\n",
    "\n",
    "    geoid = geoid[['area_name', 'geoid']]\n",
    "\n",
    "    # create new dataframe\n",
    "    educationDistribution = pd.DataFrame(data)\n",
    "    educationDistribution = pd.merge(educationDistribution, geoid, how='inner', on=['area_name'])\n",
    "    educationDistribution = educationDistribution[['geoid','area_name','geometry','Total', 'No schooling completed','Nursery school', 'Kindergarten','1st grade', '2nd grade','3rd grade', '4th grade','5th grade', '6th grade','7th grade', '8th grade','9th grade', '10th grade','11th grade','12th grade, no diploma','Regular high school diploma','GED or alternative credential','Some college, less than 1 year','Some college, 1 or more years, no degree',\"Associate's degree\",\"Bachelor's degree\",\"Master's degree\",'Professional school degree','Doctorate degree']]\n",
    "\n",
    "    # aggregate columns\n",
    "    lessHS = []\n",
    "    HSno = []\n",
    "    HSged = []\n",
    "    someColl = []\n",
    "    under = []\n",
    "    grad = []\n",
    "    # iterate through rows\n",
    "    for id in range(0,len(educationDistribution)):\n",
    "        temp = educationDistribution.iloc[id]\n",
    "        preK = [float(i) for i in temp[5]]\n",
    "        k = [float(i) for i in temp[6]]\n",
    "        fir = [float(i) for i in temp[7]]\n",
    "        sec = [float(i) for i in temp[8]]\n",
    "        thir = [float(i) for i in temp[9]]\n",
    "        four = [float(i) for i in temp[10]]\n",
    "        fif = [float(i) for i in temp[11]]\n",
    "        six = [float(i) for i in temp[12]]\n",
    "        sev = [float(i) for i in temp[13]]\n",
    "        eig = [float(i) for i in temp[14]]\n",
    "        nin = [float(i) for i in temp[15]]\n",
    "        ten = [float(i) for i in temp[16]]\n",
    "        ele = [float(i) for i in temp[17]]\n",
    "        tweNo = [float(i) for i in temp[18]]\n",
    "        twe = [float(i) for i in temp[19]]\n",
    "        ged = [float(i) for i in temp[20]]\n",
    "        collegeLE1 = [float(i) for i in temp[21]]\n",
    "        collegeGE1 = [float(i) for i in temp[22]]\n",
    "        assoc = [float(i) for i in temp[23]]\n",
    "        bach = [float(i) for i in temp[24]]\n",
    "        mast = [float(i) for i in temp[25]]\n",
    "        prof = [float(i) for i in temp[26]]\n",
    "        doct = [float(i) for i in temp[27]]\n",
    "        res1 = []\n",
    "        res2 = []\n",
    "        res3 = []\n",
    "        res4 = []\n",
    "        res5 = []\n",
    "        res6 = []\n",
    "        for i in range(0, len(preK)):\n",
    "            res1.append(preK[i]+k[i]+fir[i]+sec[i]+thir[i]+four[i]+fif[i]+six[i]+sev[i]+eig[i])\n",
    "            res2.append(nin[i]+ten[i]+ele[i]+tweNo[i])\n",
    "            res3.append(twe[i]+ged[i])\n",
    "            res4.append(collegeLE1[i]+collegeGE1[i])\n",
    "            res5.append(assoc[i]+bach[i])\n",
    "            res6.append(mast[i]+prof[i]+doct[i])\n",
    "        lessHS.append(res1)\n",
    "        HSno.append(res2)\n",
    "        HSged.append(res3)\n",
    "        someColl.append(res4)\n",
    "        under.append(res5)\n",
    "        grad.append(res6)\n",
    "\n",
    "    educationDistribution['Less than High School'] = lessHS\n",
    "    educationDistribution['High School, No Diploma'] = HSno\n",
    "    educationDistribution['High School/GED or alternative credential'] = HSged\n",
    "    educationDistribution['Some College, No Degree'] = someColl\n",
    "    educationDistribution['Undergraduate Degree'] = under\n",
    "    educationDistribution['Graduate Degree'] = grad\n",
    "\n",
    "    # clean up formatting of the columns\n",
    "    educationDistribution = educationDistribution[['geoid', 'area_name', 'geometry', 'No schooling completed','Less than High School','High School, No Diploma', 'High School/GED or alternative credential', 'Some College, No Degree','Undergraduate Degree','Graduate Degree']]\n",
    "\n",
    "    # save to .csv\n",
    "    educationDistribution.to_csv(path + 'educationDistribution{}.csv'.format(year), index=False)\n",
    "\n",
    "    # save to pickle\n",
    "    with open(path + 'educationDistribution{}.pickle'.format(year), 'wb') as file:\n",
    "        pickle.dump(educationDistribution, file)\n",
    "\n",
    "    # return new dataframe\n",
    "    return educationDistribution\n",
    "\n",
    "def splitEducationDistributions(educationDistribution,year):\n",
    "    noSchooling = educationDistribution[['geoid', 'area_name', 'No schooling completed']]\n",
    "    lessThanHS = educationDistribution[['geoid', 'area_name','Less than High School']]\n",
    "    HSNoDegree = educationDistribution[['geoid', 'area_name','High School, No Diploma']]\n",
    "    HSDegree = educationDistribution[['geoid', 'area_name','High School/GED or alternative credential']]\n",
    "    someCollege = educationDistribution[['geoid', 'area_name','Some College, No Degree']]\n",
    "    undergrad = educationDistribution[['geoid', 'area_name','Undergraduate Degree']]\n",
    "    graduate = educationDistribution[['geoid', 'area_name','Graduate Degree']]\n",
    "\n",
    "    # save to .csv\n",
    "    noSchooling.to_csv(path + 'educationDistributionA{}.csv'.format(year), index=False)\n",
    "    lessThanHS.to_csv(path + 'educationDistributionB{}.csv'.format(year), index=False)\n",
    "    HSNoDegree.to_csv(path + 'educationDistributionC{}.csv'.format(year), index=False)\n",
    "    HSDegree.to_csv(path + 'educationDistributionD{}.csv'.format(year), index=False)\n",
    "    someCollege.to_csv(path + 'educationDistributionE{}.csv'.format(year), index=False)\n",
    "    undergrad.to_csv(path + 'educationDistributionF{}.csv'.format(year), index=False)\n",
    "    graduate.to_csv(path + 'educationDistributionG{}.csv'.format(year), index=False)\n",
    "    \n",
    "    # save to .pickle\n",
    "    with open(path + 'educationDistributionA{}.pickle'.format(year), 'wb') as file: # no schooling\n",
    "        pickle.dump(noSchooling, file)\n",
    "    with open(path + 'educationDistributionB{}.pickle'.format(year), 'wb') as file: # less than High School\n",
    "        pickle.dump(lessThanHS, file)\n",
    "    with open(path + 'educationDistributionC{}.pickle'.format(year), 'wb') as file: # High School, no degree\n",
    "        pickle.dump(HSNoDegree, file)\n",
    "    with open(path + 'educationDistributionD{}.pickle'.format(year), 'wb') as file: # High School degree/GED\n",
    "        pickle.dump(HSDegree, file)\n",
    "    with open(path + 'educationDistributionE{}.pickle'.format(year), 'wb') as file: # Some college, no degree\n",
    "        pickle.dump(someCollege, file)\n",
    "    with open(path + 'educationDistributionF{}.pickle'.format(year), 'wb') as file: # Undergraduate degree\n",
    "        pickle.dump(undergrad, file)\n",
    "    with open(path + 'educationDistributionG{}.pickle'.format(year), 'wb') as file: # Graduate degree\n",
    "        pickle.dump(graduate, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b750b93",
   "metadata": {},
   "source": [
    "## Household Income "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a21f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2022 = pd.read_csv(path + 'cleanHouseholdIncome2022.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2022 = createIncomeDistributions(racial_population_with_geometry, householdIncome2022, Blockgroup_boundary, path, '2022')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2022.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15264925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2021 = pd.read_csv(path + 'cleanHouseholdIncome2021.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2021 = createIncomeDistributions(racial_population_with_geometry, householdIncome2021, Blockgroup_boundary, path, '2021')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2021.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b424c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2020 = pd.read_csv(path + 'cleanHouseholdIncome2020.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2020 = createIncomeDistributions(racial_population_with_geometry, householdIncome2020, Blockgroup_boundary, path, '2020')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2019 = pd.read_csv(path + 'cleanHouseholdIncome2019.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2019 = createIncomeDistributions(racial_population_with_geometry, householdIncome2019, Blockgroup_boundary, path, '2019')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2019.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e469fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2018 = pd.read_csv(path + 'cleanHouseholdIncome2018.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2018 = createIncomeDistributions(racial_population_with_geometry, householdIncome2018, Blockgroup_boundary, path, '2018')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2018.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67398cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2017 = pd.read_csv(path + 'cleanHouseholdIncome2017.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2017 = createIncomeDistributions(racial_population_with_geometry, householdIncome2017, Blockgroup_boundary, path, '2017')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2017.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa473e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "householdIncome2016 = pd.read_csv(path + 'cleanHouseholdIncome2016.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "incomeDistribution2016 = createIncomeDistributions(racial_population_with_geometry, householdIncome2016, Blockgroup_boundary, path, '2016')\n",
    "\n",
    "# preview data\n",
    "incomeDistribution2016.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c5a510",
   "metadata": {},
   "source": [
    "## Educational Attainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50567ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2022 = pd.read_csv(path + 'cleanEducation2022.csv')\n",
    "\n",
    "# apply createDistributnmentions function\n",
    "educationDistribution2022 = createEducationDistributions(racial_population_with_geometry, education2022, Blockgroup_boundary, path, '2022')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2022,'2022')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2022.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2021 = pd.read_csv(path + 'cleanEducation2021.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "educationDistribution2021 = createEducationDistributions(racial_population_with_geometry, education2021, Blockgroup_boundary, path, '2021')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2021,'2021')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2021.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524b6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2020 = pd.read_csv(path + 'cleanEducation2020.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "educationDistribution2020 = createEducationDistributions(racial_population_with_geometry, education2020, Blockgroup_boundary, path, '2020')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2020,'2020')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2020.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b67178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2019 = pd.read_csv(path + 'cleanEducation2019.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "educationDistribution2019 = createEducationDistributions(racial_population_with_geometry, education2019, Blockgroup_boundary, path, '2019')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2019,'2019')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2019.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06289e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2018 = pd.read_csv(path + 'cleanEducation2018.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "educationDistribution2018 = createEducationDistributions(racial_population_with_geometry, education2018, Blockgroup_boundary, path, '2018')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2018,'2018')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2018.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebc17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2017 = pd.read_csv(path + 'cleanEducation2017.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "educationDistribution2017 = createEducationDistributions(racial_population_with_geometry, education2017, Blockgroup_boundary, path, '2017')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2017,'2017')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2017.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "education2016 = pd.read_csv(path + 'cleanEducation2016.csv')\n",
    "\n",
    "# apply createDistributions function\n",
    "educationDistribution2016 = createEducationDistributions(racial_population_with_geometry, education2016, Blockgroup_boundary, path, '2016')\n",
    "\n",
    "# split into separate dataframes\n",
    "splitEducationDistributions(educationDistribution2016,'2016')\n",
    "\n",
    "# preview data\n",
    "educationDistribution2016.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
